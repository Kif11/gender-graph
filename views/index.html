<!DOCTYPE html>
<html>

<head>
  <title>Gender Graph</title>

  <meta name="viewport" content="width=device-width, initial-scale=1">

  <!-- Scripts -->
  <script
  src="https://code.jquery.com/jquery-3.2.1.min.js"
  integrity="sha256-hwg4gsxgFZhOsEEamdOYGBf13FyQuiTwlAQgxVSNgt4="
  crossorigin="anonymous"></script>
  <!-- Using https://github.com/js-cookie/js-cookie -->
  <script src="js/cookie.js"></script>
  <script>
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
    m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

    ga('create', 'UA-100222662-1', 'auto');
    ga('send', 'pageview');
  </script>

  <!-- Styles -->
  <link rel="stylesheet" type="text/css" href="css/main.css">

  <!-- Icon -->
  <link rel="icon" href="/img/favicon.png" type="image/x-icon">

  <!-- Font -->
  <link href="https://fonts.googleapis.com/css?family=Roboto|Roboto+Slab" rel="stylesheet">

  <!-- Emoji -->
  <link href="https://afeld.github.io/emoji-css/emoji.css" rel="stylesheet">

</head>

<body>

  <div id="main-col">
    <div id="center-div">
      <h1>Gender graph</h1>

      <div id="higlight">
        <p>
          Ever wonder if we can quantify a gender bias in society?
        </p>
        <p>
          Using machine learning, we can generate word associations present in a given media source.
          By looking at those assotiations we can tell how closely words are related to women or men.
          The Gender Graph project allows users to plot where words lie on a scale of "he" to "she" based on a selected media source.
        </p>
        <p>
          Enter your words and observe the differences that exist in the way we perceive gender.
        </p>
      </div>

      <div class="expandable-block" id="read-more-intro" style="display:none">
        <div id="description">
          <h2>Manifesto</h2>
          <p>
            Observing this chart clearly reveals that the media commonly associates toxic
            words with women. We consume this media every day therefore subliminally
            inherit these biases. Much of our community believes that feminism isn’t
            relevant anymore as women and men have “equal rights”. Hopefully this scientific
            evidence will be concrete proof of the disparities that exist in the way we perceive
            gender, and that we still have a long way to go.
          </p>
        </div>
        <div id="model-info">
          <h2>Traning sources</h2>

          <p>The Gender Graph Project currently has three models trained</p>

          <li><a href="http://mattmahoney.net/dc/textdata">Wiki</a> is the dump of English Wikipedia which include 70 000 unique words. This dataset is also know as text8</li>
          <li><a href="https://github.com/linanqiu/reddit-dataset"> Reddit </a> include on ~1.7 billion publicly available Reddit comments. It's include 2 milions unique words</li>
          <li><a href="http://www.softnet.tuc.gr/~ioannou/newsarticles.html">Google News</a> includes 94 829 news artiles, posted in Google News website</li>


        </div>
      </div>
      <a href="javascript: void(0)" class="expander-btn" target="read-more-intro" defaultText="Read more >" onClick="handleExpandClick(this)"></a>

      <div id=graph-container>
        <div id="input-container">
          <select class="input-item" id="model-dropdown">
            <option value="wiki">Wikipedia </option>
            <option value="reddit">Reddit</option>
            <option value="gnews">Google News</option>
          </select>
          <button class="input-item button" type="button" id="add-word-btn">Add Word</button>
          <input class="input-item input-box" id="new-word-input" type="text" name="newWord">
          <div class="spinner"></div>
          <div class="input-item status-bar"></div>
        </div> <!-- End of input container -->

        <div id="graph-canvas"></div>

      </div>


      <div id="how-it-works-section" style="display:none">

        <h1>How does it work?</h1>
        <p>
          In order for computer to understand english words, they need to be
          converted to numbers. In particular each word can be represented as a
          point in multidimensional space. It can be roughly visualized in two dimensions.
        </p>
        <video id="scater-words-video" autoplay loop>
          <source src="mov/scattered_words.mp4" type="video/mp4">
          Your browser does not support the video tag.
        </video>
        <p>
          We use the word2vec tool to generate these word vectors based on semantic
          relationships between words in a given text source. This collection of word
          vectors is called a model. We wrote <i class="em em-octocat"></i> <a href="https://github.com/sneha-belkhale/gender-word-plots" target="_blank">custom tool</a> that uses this model to
          score user words in relationship to given pair of words (in our case he and she).
        </p>
        <p>
          In order to quantify if a word is more commonly associated with women
          or men, we can find how far away this word is positioned from “she” and “he”.
          Mathematically, it can be accomplished by finding the vector direction
          between “she” and “he”, and projecting user words onto this vector using
          simple vector properties such as the dot product.
        </p>

        <div class="video-container">
          <video id="vector-projections-video" autoplay loop>
            <source src="mov/vector_projections.mp4" type="video/mp4">
            Your browser does not support the video tag.
          </video>
        </div>

        <p>
          The length of the projection onto this axis gives us an association score,
          where values closer to 0.0 are related to “he”, and values closer to 1.0 are related to “she”.
        </p>
        <p>
          This approach give us a very good picture of semantic biases in the media. However, it is important to understand that in reality
          these models are not perfect. Factors such as data quantity, quality, and algorithmic imperfections may introduce
          noise into the model.

        </p>


      </div> <!-- end of how it works section -->
      <a href="javascript: void(0)" class="expander-btn" target="how-it-works-section" defaultText="How does it work? >" onClick="handleExpandClick(this)"></a>


      <div id="credits">
        Created by <a href="https://snehabelkhale.wordpress.com/" target="_blank">Sneha Belkhale</a> and <a href="https://kiko3d.wordpress.com/" target="_blank">Kirill Kovalevskiy</a><br>
        <!--
        Check our <a href="https://github.com/sneha-belkhale/gender-word-plots">command line tool</a> for generating scores for any word pair.
        -->
      </div>

    </div> <!-- end of center-div -->
  </div>

</body>

<script src="js/index.js"></script>

</html>
